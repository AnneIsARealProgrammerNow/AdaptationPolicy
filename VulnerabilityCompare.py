import sys, os
import pandas as pd
import numpy as np
#from sklearn.linear_model import LinearRegression
import statsmodels.formula.api as sm
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib as mpl
from matplotlib.colors import LogNorm, SymLogNorm
from matplotlib import rc
from mpl_toolkits.axes_grid1 import make_axes_locatable
import matplotlib.gridspec as gridspec
from datetime import date
from adjustText import adjust_text, get_renderer, get_bboxes
from scipy.stats import zscore, spearmanr, pearsonr
#%% File locations

os.chdir (r'C:\Users\ajsie\OneDrive - University of Leeds\Adaptation policy')
#Documents per country
countryDocs =r'data/forGeoMap.csv'
countryDf = pd.read_csv(countryDocs, encoding="UTF-8")
#Split up Americas again
countryDf.loc[countryDf['Code'].isin(['CAN', 'MEX', 'USA']), 'UN continental'] = 'North America'
countryDf.loc[countryDf['UN continental'] == 'Americas', 'UN continental'] = 'South America'
countryDf['Region'] = countryDf['UN continental']
#Add publication year bc I did not export it in the GeoMap file
stmDf = pd.read_csv(r'C:\Users\ajsie\OneDrive - University of Leeds\Adaptation policy\Topic models\topic model 2\forSTM_new.csv')
countryDf = countryDf.merge(stmDf[['id', 'PY']], how='left', on='id')

#ND-GAIN scores
gain = r"data\GAIN\gain\gain.csv" #score
gainGDP = r"data\GAIN\gain\gain_delta.csv" #GDP adjusted score
gainVul =  r"data\GAIN\vulnerability\vulnerability.csv" #vulnerability
gainVulGDP = r"data\GAIN\vulnerability\vulnerability_delta.csv" #GDP adjusted vulnerability
gainDf = pd.read_csv(gain, encoding="UTF-8")
gdpDf = pd.read_csv(gainGDP, encoding="UTF-8")
vulDf = pd.read_csv(gainVul, encoding="UTF-8")
vulGdpDf = pd.read_csv(gainVulGDP, encoding="UTF-8")


#Taking files from the National Communications project
os.chdir(r'C:\Users\ajsie\OneDrive - University of Leeds\TRAC3\SisterPaper')
#CRI - NB: old version!
cri = r"CRI2020.csv"

#physical vulnerability - PVCCI - Feidouno et al., 2020
pvcci = r"PVCCI_all.csv"

#Enviornmental performance index (Yale)
epi = r"epi2020.csv"

#World risk index
wri = r"World Risk Index\wri_index_value.csv"
wriVul = r"World Risk Index\wri_vulnerability_value.csv"
wriAdapt = r"World Risk Index\wri_lackAdapt_value.csv"

#INFORM
inf = r"Inform2022.xlsx"

#Emissions data
ghg = "GCB2021v34_MtCO2_flat.csv" #"total-ghg-emissions.csv"
# ghgC = "per-capita-ghg-emissions.csv"
# ghgCu = "cumulative-co-emissions.csv"

#country codes & info to add
countryInfo = r"C:\Users\ajsie\OneDrive - University of Leeds\adaptation dataset\CountryCodes2.csv"
countryPop = r"C:\Users\ajsie\OneDrive - University of Leeds\Adaptation policy\data\Population\WPP2022_TotalPopulationBySex.csv" 

criDf = pd.read_csv(cri, encoding="UTF-8")
pvDf = pd.read_csv(pvcci, encoding = "UTF-8")
epiDf = pd.read_csv(epi, encoding = "UTF-8")
wriDf = pd.read_csv(wri, encoding = "UTF-8")
wriVulDf = pd.read_csv(wriVul, encoding = "UTF-8")
wriAdaptDf = pd.read_csv(wriAdapt, encoding = "UTF-8")
infDf = pd.read_excel(inf)

ghgDf = pd.read_csv(ghg, encoding="ANSI")
#ghgCDf = pd.read_csv(ghgC, encoding="UTF-8")
#ghgCuDf = pd.read_csv(ghgCu, encoding="UTF-8")

infoDf = pd.read_csv(countryInfo, encoding="UTF-8")
popDf = pd.read_csv(countryPop, encoding="UTF-8")
popDf = popDf[popDf['Variant'] == 'Medium']

#Revert
os.chdir (r'C:\Users\ajsie\OneDrive - University of Leeds\Adaptation policy')

#%% Create a df with per year and per country, how many documents were published + all info
df = pd.DataFrame()
df[['id', 'Country', 'Region', 'PY']] = countryDf[['id', 'Alpha-3','Region', 'PY']] #countries region (no capitals for DiffDf)
df = df.groupby(['Country', 'PY', 'Region'])['id'].count(
    ).reset_index().rename(columns = {'id': 'count'})

#Add basic info
infoDf.rename(columns = {'Country': 'Name'}, inplace=True)
infoDf.rename(columns = {'Alpha-3': 'Country'}, inplace=True) #If in one line, the double names trips pandas up
df = df.merge(infoDf[['Country', 'Name']], how='left')
df = df.merge(popDf[['ISO3_code', 'PopTotal', 'Time']],
              left_on = ['Country', 'PY'], right_on = ['ISO3_code', 'Time'], how='left')

# gdf = pd.melt(gainDf, id_vars = ['ISO3', 'Name'], var_name = 'PY', value_name = 'gainYr', )
# gdf = gdf.astype({'PY': float})
# df = df.merge(gdf, how = 'left', left_on = ['Country', 'PY'], right_on = ['ISO3', 'PY'])
# Take ND-GAIN score of publication year, or closest available
df['gainYr'] = pd.Series(dtype=float)
for i, r in df.iterrows():
    y = int(r['PY'])
    if y == 0:
        continue #Unknown year
    if y <= 1995: y = 1995 #earliest year of nd gain scores
    if y >= 2020: y = 2020 #latest year of nd gain scores
    c = r['Country'] #country
    #Get gain score (yearly column) for country & write to df
    val = gainDf[str(y)].loc[gainDf["ISO3"] == c].values
    if val.shape[0] == 1:
        df['gainYr'][i] = val[0]

#We may want to work with the mean instead
gdf = pd.DataFrame()
gdf[['Country']] = gainDf[['ISO3']]
gdf['gain_Avg'] = gainDf[[str(n) for n in range(1995, 2021)]].mean(axis=1)
df = df.merge(gdf, how='left', on='Country')

#cri info we do not have yearly & uses full country names
criDf.rename(columns={'CRI_score': 'CRI_score_2020', 'Country': 'Name'}, inplace=True)
df = pd.merge(df, criDf[['Name','CRI_score_2020']], 
              how='left', on = 'Name')

#Add physical vulnerability and environmental performance index
pvDf.rename(columns={"iso_3":"Country"}, inplace=True)
df = pd.merge(df, pvDf[['Country','PVCCI', 'PVCCI3']], 
              how='left', on='Country')

epiDf.rename(columns={"EPI.new": "epi", "iso":"Country"}, inplace=True)
df = pd.merge(df, epiDf[['Country','epi']], 
              how='left', on='Country')

#WRI similar to ND-GAIN
df['wriYr'] = pd.Series(dtype=float)
for i, r in df.iterrows():
    y = int(r['PY'])
    if y == 0:
        continue #Unknown year
    if y <= 2011: y = 2011 #earliest year of wri gain scores
    if y >= 2021: y = 2021 #latest year of wri gain scores
    c = r['Country'] #country
    #Get gain score (yearly column) for country & write to df
    val = wriDf[str(y)].loc[wriDf["ISO"] == c].values
    if val.shape[0] == 1:
        df['wriYr'][i] = val[0]
#And mean
wdf = pd.DataFrame()
wdf[['Country']] = wriDf[['ISO']]
wdf['wri_Avg'] = wriDf[[str(n) for n in range(2011, 2022)]].mean(axis=1)
df = pd.merge(df, wdf, how='left',on='Country')

#Inform has both indices in one 
infDf.rename({
    'Hazard': 'hazInf', 
    'Vulnerability': 'vulInf',
    'Coping': 'copInf'},    
    inplace=True, axis=1)
df = pd.merge(df, infDf[['ISO3','hazInf', 'vulInf', 'copInf', 'Inform']]
              , how='left', left_on='Country', right_on='ISO3')

#check if there are any countries for which we have topic scores but no cri score
nanDf = df[df.isna().any(axis=1)]
print(f"number of rows with at least one missing index value: {nanDf.shape[0]}")

#emissions data
ghgDf.rename({"ISO 3166-1 alpha-3": "Code"}, axis = 1, inplace=True)
#Dataset goes back to pre-industrial, so we can simply cumsum per country for cumulative
ghgDf["cumulative"] = ghgDf.groupby('Code')['Total'].cumsum()
ghgDf["cumulativeCapita"] = ghgDf.groupby('Code')['Per Capita'].cumsum()

df = df.merge(ghgDf[['Code', 'Year', 'Total', 'cumulative', 'cumulativeCapita']], 
              how='left', left_on = ['Country', 'PY'], right_on = ['Code', 'Year'])


#%% Layout function
sns.set({'font.sans-serif':['Open Sans']})

def TitleAndSave(fig, ax, title, subtitle, save=False, big = False, tight=True):
    """Give a matplotlib fig and ax with desired title and subtitle. 
        Save can be changed to STR to save with that name & a date prefix
    """ 
    if big == False:
        sns.set(font_scale=1, font= 'Arial')
        ax.text(x=0.5, y=1.1, s=title, fontsize=14, weight='bold', ha='center', va='bottom', transform=ax.transAxes)
        ax.text(x=0.5, y=1.03, s=subtitle, fontsize=12, ha='center', va='bottom', transform=ax.transAxes)
    elif big == 'grouped':
        sns.set(font_scale=1, font= 'Arial')
        ax.text(x=0.5, y=1.25, s=title, fontsize=14, weight='bold', ha='center', va='bottom', transform=ax.transAxes)
        ax.text(x=0.5, y=1.15, s=subtitle, fontsize=12, ha='center', va='bottom', transform=ax.transAxes)
    else:
        sns.set({'xtick.bottom': True}, font_scale=0.6, font= 'Arial', rc={"lines.linewidth": 2.5})
        ax.text(x=0.5, y=1.12, s=title, fontsize=14, weight='bold', ha='center', va='bottom', transform=ax.transAxes)
        ax.text(x=0.5, y=1.05, s=subtitle, fontsize=12, ha='center', va='bottom', transform=ax.transAxes)

    if tight == True: fig.tight_layout(rect=[0, 0, 1, 0.98])
    
    if save: fig.savefig(f'plots/{date.today()}_{save}.png')
    
    return fig, ax

#%% Plotting function

def plot_by_region(fig, axes, scoreCols, valueVars, dfs, regression = False, order=1,
                   xlabels = False, invert= False,
                   regionMarkers = { 'Oceania': 'o',
                                    'Europe': 'X',
                                    'North America': 's',
                                    'Asia': 'P',
                                    'Africa': 'D',
                                    'South America': '*'},
                   separateYAxis=False,
                   colours = sns.color_palette(),
                   customPalette = False,
                   xlog = False, linthreshx = 10, linscalex=2.5,
                   legend ="default",
                   title ='Number of times a place in a country is mentioned by country vulnerability',
                   ):
    

    #plot scores coloured by type of score, with marker by region
    n=0
    for ax, score in zip(axes, scoreCols):
        
        #to be able to plot from multiple dfs, you can input them as a list
        #NB: the order needs to line up with the score rows!
        if type(dfs) == list:
            df = dfs[n]
        else: df = dfs
        
        #Plot scatter -- first melt data
        meltDf = pd.melt(df, id_vars=[score, "Region"], 
                                     value_vars= valueVars)
        
        #Formatting options depending on size/legend input
        if len(meltDf) >= 800: 
            markersize=20
            alpha = .65
        else: 
            markersize =35
            alpha = 0.75
        if legend == "default": l = False
        else: l = True
             
        
        if customPalette == False:
            for m in regionMarkers:
                sns.scatterplot(data=meltDf.loc[meltDf['Region'] == m],
                            x=score, y="value", hue="variable", marker = regionMarkers[m],
                            s = markersize,
                            ax=ax, alpha=alpha, legend=l)
        else: 
            for m in regionMarkers:
                sns.scatterplot(data=meltDf.loc[meltDf['Region'] == m],
                            x=score, y="value", hue="variable", marker = regionMarkers[m],
                            s = markersize, palette = customPalette,
                            ax=ax, alpha=alpha, legend=l)
        
        #Add regression line on top if needed
        if regression == True:
            for value, c in zip(valueVars, colours):
                sns.regplot(data=meltDf.loc[meltDf['variable'] == value],
                    x=score, y="value", # hue="variable", 
                    scatter=False, ci=False, order=order,
                     #markers=["o", "X", "s", "D", "v", "P"],
                    ax=ax, 
                    line_kws = {'color':c, 'alpha' :0.85,
                                'linestyle' : 'dashed'})
                
        #Invert the axis to match the inverted data
        #NB: just flips, so if you run it twice, the axis is back to normal         
        if type(invert) == list:
            if invert[n] == True:
                ax.invert_xaxis()
                
        ax.set_ylabel("Share of places mentioned", weight="bold")
 
        if type(xlabels) == list:
            ax.set_xlabel(xlabels[n], weight="bold")
        else: ax.set_xlabel(score, weight="bold")
        
        
        
        if type(xlog) == list:
            if xlog[n] == 'symlog':
                ax.set_xscale('symlog', linthresh =linthreshx[n], linscale = linscalex[n])
                plt.gca().xaxis.grid(True, which='minor')
            elif xlog[n] == True:
                ax.set_xscale('log')
        elif xlog == 'symlog':
            ax.set_xscale('symlog', linthresh =linthreshx, linscale = linscalex)
            plt.gca().xaxis.grid(True, which='minor')
        elif xlog == True:
            ax.set_xscale('log')
            
        n += 1
        
    #Add a single legend for all
    ax1 = axes[0]
    if legend == "default":
        # # empty plots with the right colours/labels
        # h1 = ax1.scatter([], [], alpha=0, label="Scoretype")
        # h2 = [ax1.scatter([], [], color = c, label=l) for l, c in zip(["Relative", "Relative incl. pop"], colours)]
        # he = ax1.scatter([], [], alpha=0, label=" ") #empty for spacing 
        h4 = ax1.scatter([], [], alpha=0, label="Region")
        h5 = [ax1.scatter([], [],  label= m, c = 'k', marker = regionMarkers[m]) for m in regionMarkers]
        handles, labels = ax1.get_legend_handles_labels()
    else:
        handles, labels = ax1.get_legend_handles_labels()
        [ax.get_legend().remove() for ax in axes]

        
    
    ax1.legend(handles, labels, loc='center right', bbox_to_anchor=(1.1, 0.5),  
               bbox_transform=plt.gcf().transFigure)
    
    fig.suptitle(title, 
                 y = 0.95,
                 fontsize=16, weight='bold')
    fig.tight_layout()
    
    
    
    return(fig, axes)

#%% create plots
fig = plt.figure(figsize=(10,10), dpi=300)

spec = gridspec.GridSpec(ncols=2, nrows=3, figure=fig, hspace=0.25,wspace=0.25)
ax1 = fig.add_subplot(spec[0, 0])
ax2 = fig.add_subplot(spec[0, 1])
ax3 = fig.add_subplot(spec[1, 0])
ax4 = fig.add_subplot(spec[1, 1])
ax5 = fig.add_subplot(spec[2,:])

axes = [ax1, ax2, ax3, ax4, ax5]
scoreRows = ['CRI_score_2020', 'Inform', 'epi', 'wriYr', 'gainYr' ]#['gain_Avg', 'gainGdp_Avg', 'vul_Avg', 'vulGdp_Avg', 'CRI_score_avg']
valueVars = ['count'] # 'CCT_avg']


fig, axes = plot_by_region(fig, axes, scoreRows, valueVars, df, 
                           #invert = [True, False, False, True],
                           regression=True)



#%% Clearly the overall growth of the dataset massively skews results
# => convert count to % of total for that year
try:
    df = dfSave
except:
    dfSave = df

#We need to discard some values though
df = df[df['PY'] >=2000] #Before, not even ten places per year so results highly unreliable
# #Only keep entries with docs in at least 3 different years
# for c in df['Country'].unique():
#     if len(df[df['Country'] ==c]) <3:
#         df = df[df['Country'] !=c]


df['countPercent'] = pd.Series(dtype='float')
for y in df['PY'].unique(): 
    tot = df.loc[df['PY'] == y, 'count'].sum()
    df.loc[df['PY'] == y, 'countPercent'] = df['count']/tot
   
fig = plt.figure(figsize=(10,10), dpi=300)

spec = gridspec.GridSpec(ncols=2, nrows=3, figure=fig, hspace=0.25,wspace=0.25)
ax1 = fig.add_subplot(spec[0, 0])
ax2 = fig.add_subplot(spec[0, 1])
ax3 = fig.add_subplot(spec[1, 0])
ax4 = fig.add_subplot(spec[1, 1])
ax5 = fig.add_subplot(spec[2,:])

axes = [ax1, ax2, ax3, ax4, ax5]
scoreRows = ['CRI_score_2020', 'Inform', 'epi', 'wriYr', 'gainYr' ]#['gain_Avg', 'gainGdp_Avg', 'vul_Avg', 'vulGdp_Avg', 'CRI_score_avg']
valueVars = ['countPercent']

fig, axes = plot_by_region(fig, axes, scoreRows, valueVars, df, 
                           invert = [True, False, True, False, True],
                           regression=True)

#%% Better. Let's see if average per country gives a clearer image

dfAv = df.groupby(['Country', 'Region'], as_index=False).mean() #Small difference between some values e.g. gainYr and gainAvg caused by None and/or years without publications

fig = plt.figure(figsize=(10,10), dpi=300)

spec = gridspec.GridSpec(ncols=2, nrows=3, figure=fig, hspace=0.25,wspace=0.25)
ax1 = fig.add_subplot(spec[0, 0])
ax2 = fig.add_subplot(spec[0, 1])
ax3 = fig.add_subplot(spec[1, 0])
ax4 = fig.add_subplot(spec[1, 1])
ax5 = fig.add_subplot(spec[2,:])

axes = [ax1, ax2, ax3, ax4, ax5]
scoreRows = ['CRI_score_2020', 'Inform', 'epi', 'wriYr', 'gainYr' ]#['gain_Avg', 'gainGdp_Avg', 'vul_Avg', 'vulGdp_Avg', 'CRI_score_avg']
valueVars = ['countPercent']

fig, axes = plot_by_region(fig, axes, scoreRows, valueVars, dfAv, 
                           invert = [True, False, True, False, True],
                           xlabels = ['Climate Risk Index', 'INFORM', 'Environmental Performance Index', 'World Risk Index', 'ND-GAIN'],
                           regression=True)


#%% As sum
dfSum = df.groupby(['Country', 'Region'], as_index=False).sum()
for c in dfSum.columns:
    if c not in ['count', 'countPercent']:
        dfSum[c] = dfAv[c]
        

fig = plt.figure(figsize=(10,10), dpi=300)

spec = gridspec.GridSpec(ncols=2, nrows=3, figure=fig, hspace=0.25,wspace=0.25)
ax1 = fig.add_subplot(spec[0, 0])
ax2 = fig.add_subplot(spec[0, 1])
ax3 = fig.add_subplot(spec[1, 0])
ax4 = fig.add_subplot(spec[1, 1])
ax5 = fig.add_subplot(spec[2,:])

axes = [ax1, ax2, ax3, ax4, ax5]
scoreRows = ['CRI_score_2020', 'Inform', 'epi', 'wriYr', 'gainYr' ]#['gain_Avg', 'gainGdp_Avg', 'vul_Avg', 'vulGdp_Avg', 'CRI_score_avg']
valueVars = ['count']

fig, axes = plot_by_region(fig, axes, scoreRows, valueVars, dfSum, 
                           invert = [True, False, True, False, True],
                           xlabels = ['Climate Risk Index', 'INFORM', 'Environmental Performance Index', 'World Risk Index', 'ND-GAIN'],
                           regression=True)

#%% Averaging by population just highlights a few small countries
df['countPercentPop'] = (df['countPercent']/df['PopTotal'])*df['PopTotal']
df['countPop'] = (df['count']/df['PopTotal'])
dfAv = df.groupby(['Country', 'Region'], as_index=False).mean() #Small difference between some values e.g. gainYr and gainAvg caused by None and/or years without publications

#Maybe normalizing will help? 
for c in ['countPop' , 'countPercentPop']:
    dfAv[c] = (dfAv[c] - dfAv[c].min()) / (dfAv[c].max() - dfAv[c].min()) 
fig = plt.figure(figsize=(10,10), dpi=300)

spec = gridspec.GridSpec(ncols=2, nrows=3, figure=fig, hspace=0.25,wspace=0.25)
ax1 = fig.add_subplot(spec[0, 0])
ax2 = fig.add_subplot(spec[0, 1])
ax3 = fig.add_subplot(spec[1, 0])
ax4 = fig.add_subplot(spec[1, 1])
ax5 = fig.add_subplot(spec[2,:])

axes = [ax1, ax2, ax3, ax4, ax5]
scoreRows = ['CRI_score_2020', 'Inform', 'epi', 'wriYr', 'gainYr' ]#['gain_Avg', 'gainGdp_Avg', 'vul_Avg', 'vulGdp_Avg', 'CRI_score_avg']
valueVars = ['countPop', 'countPercentPop']

fig, axes = plot_by_region(fig, axes, scoreRows, valueVars, dfAv, 
                           invert = [True, False, True, False, True],
                           xlabels = ['Climate Risk Index', 'INFORM', 'Environmental Policy Index', 'World Risk Index', 'ND-GAIN'],
                           regression=True)





















#%% Investigate outliers
#vulnerable countries with low IAV topic scores
lowGainLowIAV = df.loc[(df["gain_Avg"] < 40) & (df["IAV_avg"] < 0.035)]
print(f"Vulnerable countries (low gain score) with LOW IAV topic scores:\n {lowGainLowIAV['Country']}")
print()
vulnerableLowIAV = df.loc[(df["vul_Avg"] > 0.5) & (df["IAV_avg"] < 0.035)]
print(f"Vulnerable countries (high vulnerability component) with LOW IAV topic scores:\n {vulnerableLowIAV['Country']}")
print()
both = list(set(lowGainLowIAV['Country']) & set(vulnerableLowIAV['Country']))
print(f"Countries in both:\n {both}") #This is all of them
print("----------")

vulnerableHighIAV = df.loc[(df["vul_Avg"] > 0.5) & (df["IAV_avg"] > 0.08)]
print(f"Vulnerable countries with HIGH IAV topic scores:\n {vulnerableHighIAV['Country']}")
print("----------")

lowGainHighMiti = df.loc[(df["gain_Avg"] < 50) & (df["Miti_avg"] > 0.04)]
print(f"Vulnerable countries (low gain score) with HIHG mitigation topic scores:\n {lowGainHighMiti['Country']}")

#
gdpOutliers = df.loc[(df["gainGdp_Avg"] < 10)]


#%% Combining publication years with vulnerability scores
df = df_allReports

#add the columns
cols = df.columns.to_list()
cols.extend(['gainYr','gainGdpYr','vulYr','vulGdpYr', 
             'wriYr', 'wriVulYr', 'wriAdaYr'])
df = df.reindex(columns = cols) 

for i, r in df.iterrows():
    #ND-GAIN
    y = r['Year'] -1 #year of report - take year predicing
    if y <= 1995: y = 1995 #earliest year of nd gain scores
    if y >= 2019: y = 2019 #latest year of nd gain scores
    y = str(y)
    c = r['ISO3'] #country
    
    #Get gain score (yearly column) for country & write to df
    val = gainDf[y].loc[(gainDf["ISO3"] == c)].values
    if val.shape[0] == 1:
        df['gainYr'][i] = val[0]
    
    #Get GDP adjusted gain score (yearly column) for country & write to df
    val = gdpDf[y].loc[(gdpDf["ISO3"] == c)].values
    if val.shape[0] == 1:
        df['gainGdpYr'][i] = val[0]
    
    #Get gain vulnerability score (yearly column) for country & write to df
    val = vulDf[y].loc[(vulDf["ISO3"] == c)].values
    if val.shape[0] == 1:
        df['vulYr'][i] = val[0]
    
    #Get gdp adjusted vulnerab. score (yearly column) for country & write to df
    val = vulGdpDf[y].loc[(vulGdpDf["ISO3"] == c)].values
    if val.shape[0] == 1:
        df['vulGdpYr'][i] = val[0]
        
        
    #same for WRI (but different years available)
    y = r['Year'] -1
    if y <= 2011: y = 2011 #earliest year of nd gain scores
    if y >= 2021: y = 2021 #latest year of nd gain scores
    y = str(y)
    
    val = wriDf[y].loc[(wriDf["ISO"] == c)].values
    if val.shape[0] == 1:
        df['wriYr'][i] = val[0]
        
    val = wriVulDf[y].loc[(wriVulDf["ISO"] == c)].values
    if val.shape[0] == 1:
        df['wriVulYr'][i] = val[0]
        
    val = wriAdaptDf[y].loc[(wriAdaptDf["ISO"] == c)].values
    if val.shape[0] == 1:
        df['wriAdaYr'][i] = val[0]
    

df_gainWriYearly = df
    


#%%Plot the yearly data

df =df_gainWriYearly 

fig2 = plt.figure(figsize=(10,10), dpi=300)

spec = gridspec.GridSpec(ncols=2, nrows=2, figure=fig2)
ax1 = fig2.add_subplot(spec[0, 0])
ax2 = fig2.add_subplot(spec[0, 1])
ax3 = fig2.add_subplot(spec[1, 0])
ax4 = fig2.add_subplot(spec[1, 1])
#ax5 = fig.add_subplot(spec[2,:])

axes = [ax1, ax2, ax3, ax4]
scoreCols = ['gainYr', 'vulYr', 'wriYr', 'CRI_score_avg']
valueVars = ['IAV_avg', 'Miti_avg'] #AV_avg', 'CCT_avg']

fig2, axes = plot_by_region(fig2, axes, scoreCols, valueVars,
                            dfs = [df, df, df, df_meanReports],
                            invert = [True, False, False, True],
                            regression = True,                            
                            title ='Topic scores vs indicator in preceding year')


fig2.tight_layout()



#%% least squares
for formula in ['Miti_avg ~ gainYr', 'IAV_avg ~ gainYr', 'Miti_avg ~ wriYr', 'IAV_avg ~ wriYr']:
    result = sm.ols(formula=formula, data=df).fit()
    print(f'\n{formula}')
    print(result.params)
    print(result.summary())
#for x, y in zip(['Miti_avg', 'Miti_avg', 'IAV_avg', 'IAV_avg'], ['gainYr', 'wriYr', 'gainYr', 'wriYr']): # for later version of sm
    # X= df[x]
    # Y= df[y]
    # sm.add_constant(X)
    # model = sm.OLS(Y,X)
    # result = model.fit()
    #print(x, y)


#%%
#Create plots per time period (1995-2003 vs 2003-2008 and 2009-2015 vs 2015-2020)
df = df_gainWriYearly
df1 = df.loc[df['Year'] < 2003]
df2 = df.loc[(df['Year'] >= 2003) & (df['Year'] <= 2008)]
df3 = df.loc[(df['Year'] >= 2009) & (df['Year'] <= 2015)]
df4 = df.loc[df['Year'] > 2015]
dfMean = df_allReports.groupby(['ISO3', 'Region', 'Country']).mean(numeric_only=True).reset_index()

fig = plt.figure(figsize=(10,10), dpi=300)


scoreRows = ['gain_Avg', 'vul_Avg', 'gainGdp_Avg', 'CRI_score_avg', 'PVCCI3', 'epi' ]#['gain_Avg', 'gainGdp_Avg', 'vul_Avg', 'vulGdp_Avg', 'CRI_score_avg']
valueVars = ['Miti_avg', 'IAV_avg'] # 'CCT_avg']

for dfn, years in zip([df1, df2, df3, df4, df, dfMean], 
                      ['pre-2003', '2003-2008', '2009-2015', '2015-2020', 'up to 2020', 'All up to 2020 - average by country']):
    
    
    fig = plt.figure(figsize=(10,10), dpi=300)
    spec = gridspec.GridSpec(ncols=2, nrows=3, figure=fig)
    ax1 = fig.add_subplot(spec[0, 0])
    ax2 = fig.add_subplot(spec[0, 1])
    ax3 = fig.add_subplot(spec[1, 0])
    ax4 = fig.add_subplot(spec[1, 1])
    ax5 = fig.add_subplot(spec[2, 0])
    ax6 = fig.add_subplot(spec[2, 1])
    
    axes = [ax1, ax2, ax3, ax4, ax5, ax6]
    
    fig, axes = plot_by_region(fig, axes, scoreRows, valueVars, dfn, 
                                          regression=True,
                                          title= f'Vulnerabilty vs topic scores - period: {years}')
    #fig.savefig(f'plots/{date.today()}_{years}_linear.png')
    
    result = sm.ols(formula="Miti_avg ~ epi", data=dfn).fit()
    print(f'\n\n{years}')
    print(result.params)
    print(result.summary())

#%% TODOs
#TODO: investigate largest shifts in CRI scores & if this impacts topic distribution
#OR other way around? Find large shifts in topic distribution and see what might have happened before?


#HEX: "#2A84AB" "#326B14" "#C76800"

#%% Final big plot - SM

#All indices for the suplementary materials
fig2 = plt.figure(figsize=(10,18), dpi=300)

spec = gridspec.GridSpec(ncols=3, nrows=7, figure=fig2)
ax1 = fig2.add_subplot(spec[0:2, 0:2])
ax2 = fig2.add_subplot(spec[0, 2])
ax3 = fig2.add_subplot(spec[1, 2])
ax4 = fig2.add_subplot(spec[2:4, 0:2])
ax5 = fig2.add_subplot(spec[2, 2])
ax6 = fig2.add_subplot(spec[3, 2])
ax7 = fig2.add_subplot(spec[4:6, 0:2])
ax8 = fig2.add_subplot(spec[4, 2])
ax9 = fig2.add_subplot(spec[5, 2])
ax10 = fig2.add_subplot(spec[6, 0])
ax11 = fig2.add_subplot(spec[6, 1])
ax12 = fig2.add_subplot(spec[6, 2])

axes = [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9, ax10, ax11, ax12]
scoreCols = ['gainYr', 'vulYr', 'gainGdpYr', 
             'wriYr', 'wriVulYr', 'wriAdaYr', 
             'Inform', 'vulInf', 'copInf',
             'CRI_score_avg', "epi", "PVCCI3",]
valueVars = ['IAV_avg', 'Miti_avg'] #AV_avg', 'CCT_avg']

fig2, axes = plot_by_region(fig2, axes, scoreCols, valueVars,
                            dfs = [df_gainWriYearly, df_gainWriYearly, df_gainWriYearly,
                                   df_gainWriYearly, df_gainWriYearly, df_gainWriYearly,
                                   df_meanReports, df_meanReports, df_meanReports,
                                   df_meanReports, df_meanReports, df_meanReports],
                            invert = [False, True, False,
                                      True, True, True, 
                                      True, True, True,
                                      False, False, True],
                            xlabels = ["ND-GAIN score", "ND-GAIN vulnerability", "ND-Gain GDP adjusted",
                                        "WRI score", "WRI vulnerability", "WRI adaptive capacity",
                                        "INFORM score", "INFORM vulnerability", "INFORM coping cap.",
                                        "CRI score", "EPI score", "Physical vulnerability score"],
                            colours = ["#326b14", "#2a84ab"],
                            customPalette= ["#326b14", "#2a84ab"],
                            regression = True,                             
                            title ='Topic scores for mitigation and IAV by country vulnerability')

ax4.set_xlim([33, None]) #Outlier of Vanuvatu makes it hard to see
for ax in axes:
    ax.set_ylim([-0.005, None])

fig2.tight_layout()

#fig2.savefig(f'plots/FinalOptions/{date.today()}_12-indices.png', bbox_inches='tight')
#%% Now add the emissions data
#data already in long form

dfEm = pd.merge(df_gainWriYearly, ghgDf, left_on= ["ISO3", "Year"], right_on=["Code", "Year"])

#%% Plot all emission options for the supplementary materials
figE = plt.figure(figsize=(10,10), dpi=300)

spec = gridspec.GridSpec(ncols=2, nrows=2, figure=figE)
axE1 = figE.add_subplot(spec[0, 0])
axE2 = figE.add_subplot(spec[0, 1])
axE3 = figE.add_subplot(spec[1, 0])
axE4 = figE.add_subplot(spec[1, 1])


axesE = [axE1, axE2, axE3, axE4]
scoreCols = ["Total", "Per Capita","cumulative", "cumulativeCapita"]
valueVars = ['IAV_avg', 'Miti_avg'] #AV_avg', 'CCT_avg']

figE, axesE = plot_by_region(figE, axesE, scoreCols, valueVars,
                            dfs = dfEm,
                            xlabels = ["Total yearly emissions " + "$(MtCO_{2})$",
                                       "Yearly per capita emissions " + "$(MtCO_{2})$", 
                                       "Cumulative emissions " +"$(MtCO_{2})$",
                                       "Cumulative per capita emissions " +"$(MtCO_{2})$",],
                            colours = ["#326b14", "#2a84ab"],
                            customPalette= ["#326b14", "#2a84ab"],
                            regression = True,                             
                            title ='Topic prevalence for mitigation and IAV topics by country emissions')

#Clip out outliers
axE1.set_xlim([-400, 6100]) #Removes China (9775)
axE3.set_xlim([-10000, 160000]) #Removes all 5 reports by the USA

for ax in axesE:
    ax.set_ylim([-0.005, None])

figE.tight_layout()
#figE.savefig(f'plots/FinalOptions/{date.today()}_AllEmissions.png', bbox_inches='tight')

#%% Main indices - paper figure?

fig3 = plt.figure(figsize=(10,10), dpi=300)

spec = gridspec.GridSpec(ncols=2, nrows=2, figure=fig3)
ax31 = fig3.add_subplot(spec[0, 0])
ax32 = fig3.add_subplot(spec[0, 1])
ax33 = fig3.add_subplot(spec[1, 0])
ax34 = fig3.add_subplot(spec[1, 1])


axes3 = [ax31, ax32, ax33, ax34]
scoreCols = ['gainYr', 'wriYr', "Per Capita","cumulative"]
valueVars = ['IAV_avg', 'Miti_avg'] #AV_avg', 'CCT_avg']

fig3, axes3 = plot_by_region(fig3, axes3, scoreCols, valueVars,
                            dfs = [df_gainWriYearly, df_gainWriYearly,
                                   dfEm, dfEm],
                            invert = [False, True, 
                                      False, False],
                            xlabels = ["ND-GAIN score", "WRI score",
                                       "Per capita emissions " + "$(MtCO_{2})$", "Cumulative emissions " +"$(MtCO_{2})$"],
                            xlog = [False, False, False, False],
                            linthreshx = [None, None, 
                                          1*10**10, 20],
                            linscalex = [None, None, 
                                          2.5, 1.5],
                            colours = ["#326b14", "#2a84ab"],
                            customPalette= ["#326b14", "#2a84ab"],
                            regression = True,                             
                            title ='Topic prevalence for mitigation and IAV topics by country vulnerability and emission')

#Clip out outliers
ax32.set_xlim([33, None]) #Note: flipped axis so 33 is upper bound, effectively removes Vanuvatu
ax33.set_xlim([-1, 24]) #Removes Qatar (39), Trinidad and Tobago (33) and Kuwait (29)
ax34.set_xlim([-6000, 110000]) #For cumulativeCapita: 2150 Removes Qatar (2942)

for ax in axes3:
    ax.set_ylim([-0.005, None])

fig3.tight_layout()
#fig3.savefig(f'plots/FinalOptions/{date.today()}_4x4cumu.png', bbox_inches='tight')



#%%Sarah's plot idea: substract mitigation from adaptation
# To work with the paper's colour scheme, we need a custom colormap
#Heavily based on: https://towardsdatascience.com/beautiful-custom-colormaps-with-matplotlib-5bab3d1f0e72

import matplotlib.colors as mcolors

def hex_to_rgb(value):
    '''
    Converts hex to rgb colours
    value: string of 6 characters representing a hex colour.
    Returns: list length 3 of RGB values'''
    value = value.strip("#") # removes hash symbol if present
    lv = len(value)
    return tuple(int(value[i:i + lv // 3], 16) for i in range(0, lv, lv // 3))


def rgb_to_dec(value):
    '''
    Converts rgb to decimal colours (i.e. divides each value by 256)
    value: list (length 3) of RGB values
    Returns: list (length 3) of decimal values'''
    return [v/256 for v in value]

def get_continuous_cmap(hex_list, float_list=None):
    ''' creates and returns a color map that can be used in heat map figures.
        If float_list is not provided, colour map graduates linearly between each color in hex_list.
        If float_list is provided, each color in hex_list is mapped to the respective location in float_list. 
        
        Parameters
        ----------
        hex_list: list of hex code strings
        float_list: list of floats between 0 and 1, same length as hex_list. Must start with 0 and end with 1.
        
        Returns
        ----------
        colour map'''
    rgb_list = [rgb_to_dec(hex_to_rgb(i)) for i in hex_list]
    if float_list:
        pass
    else:
        float_list = list(np.linspace(0,1,len(rgb_list)))
        
    cdict = dict()
    for num, col in enumerate(['red', 'green', 'blue']):
        col_list = [[float_list[i], rgb_list[i][num], rgb_list[i][num]] for i in range(len(float_list))]
        cdict[col] = col_list
    cmp = mcolors.LinearSegmentedColormap('my_cmp', segmentdata=cdict, N=256)
    return cmp




#%% Create colormap
dfEm["IAV - Mitigation score"]=dfEm["IAV_avg"]-dfEm["Miti_avg"]


divnorm = mcolors.TwoSlopeNorm(vmin=dfEm["IAV - Mitigation score"].min(),
                               vcenter=0, 
                               vmax=dfEm["IAV - Mitigation score"].max())

#hexs= ["#2a84ab","#FFFFFF", "#326b14"] #From Mitigation to white to IAV
#hexs= ["#2a84ab","#000000", "#326b14"] #From Mitigation to black to IAV
hexs = ["#0251a8","#F2F2F2", "#2e7708"] #Extra-saturated & grey
cmap=get_continuous_cmap(hexs, 
                         float_list = [0, 0.5, 1]
                                       )

#%%Plot 
#sns.set_theme() #grey bg
sns.set(style='whitegrid')

fig5 = plt.figure(figsize=(10,10), dpi=300)

spec = gridspec.GridSpec(ncols=2, nrows=2, figure=fig5)
ax51 = fig5.add_subplot(spec[0, 0])
ax52 = fig5.add_subplot(spec[0, 1])
ax53 = fig5.add_subplot(spec[1, 0:2])

axes = [ax51, ax52, ax53]


for ax, xvalue, yvalue in zip(axes, ["cumulative", "Per Capita", "Per Capita"], ['gainYr', 'gainYr', "cumulative"]):
    sns.scatterplot(data=dfEm, x=xvalue, y=yvalue, hue="IAV - Mitigation score", ax=ax, style="Region", 
                    palette= cmap, alpha=1,
                    edgecolor ="grey", linewidths = 0.5,
                    #palette="rocket_r",
                    #hue_norm = SymLogNorm(linthresh=0.01, linscale=0.1)
                    #legend="full"
                    )
    ax.set_xscale("log")
    #ax.set_ylabel("ND-GAIN Score")

ax53.set_yscale("log")

handles, labels = ax51.get_legend_handles_labels()
[ax.get_legend().remove() for ax in axes]

fig5.legend(handles, labels, loc='center right', 
            labelspacing = 1.1,
            bbox_to_anchor=(1.12, 0.5),  
            bbox_transform=plt.gcf().transFigure)


fig5.suptitle("Difference between IAV and Mitigation topics by country vulnerability and emissions", 
                 fontsize=16, weight='bold')

#fig5.savefig(f'plots/{date.today()}DifferencesPlot_emissionsAndGain_OurPallete.png', bbox_inches='tight')

#%% Ianis'idea: density plot
fig6, ax6 = plt.subplots(figsize=(10,6), dpi=300)
for yvalue, col in zip(["IAV_avg", "Miti_avg"], [ "#326b14", "#2a84ab"]):
    ax6 = sns.kdeplot(
        data=dfEm, x="cumulative", y=yvalue, color=col, alpha = 0.5, 
        fill=True, fig= fig6, ax=ax6
    )
ax6.set_xlim([-6000, 110000])
#ax6.set_xscale("log")
ax6.set_ylabel("Topic score")

fig6.suptitle("Density plot IAV and mitigation topic scores", 
                 fontsize=16, weight='bold')




#%% Joint plot
#Long form

iavs = dfEm["IAV_avg"].to_frame(name = 'Topic score')
iavs["Score"] = "IAV"
iavs["cumulative"] = dfEm["cumulative"]
mitis = dfEm["Miti_avg"].to_frame(name = 'Topic score')
mitis["Score"] = "Mitigation"
mitis["cumulative"] = dfEm["cumulative"]
both = pd.concat([iavs, mitis], ignore_index=True)

fig7, ax7 = plt.subplots(figsize=(10,6), dpi=300)

ax7 = sns.jointplot(data=both,  x="cumulative", y="Topic score", kind="kde",
                    fill=True, hue="Score",  alpha = 0.5,
                    xlim = (-6000, 110000), ax=ax7
                    )

# for yvalue, col in zip(["IAV_avg", "Miti_avg"], [ "#326b14", "#2a84ab"]):
#     ax6 = sns.displot(
#         data=dfEm, x="cumulative", y=yvalue, 
#         kind="kde", fill=True,
#         color=col, alpha = 0.5, 
#         fig= fig7, ax=ax7
#     )
#ax7.set(xlim = (-6000, 110000))
#ax7.set_xscale("log")
#ax7.set(ylabel="Topic score")

fig7.suptitle("Distribution plot IAV and mitigation topic scores", 
                 fontsize=16, weight='bold')

#%% Combination of combined emissions and linear plot for vulnerability - paper plot?

fig8 = plt.figure(figsize=(10,10), dpi=300)

spec = gridspec.GridSpec(ncols=2, nrows=2, figure=fig8, hspace= 0.25)
ax81 = fig8.add_subplot(spec[0, 0])
ax82 = fig8.add_subplot(spec[0, 1])
ax83 = fig8.add_subplot(spec[1, 0:2])


axes8 = [ax81, ax82]
scoreCols = ['gainYr', 'wriYr', "Per Capita","cumulative"]
valueVars = ['IAV_avg', 'Miti_avg'] #AV_avg', 'CCT_avg']

fig8, axes8 = plot_by_region(fig8, axes8, scoreCols, valueVars,
                            dfs = [df_gainWriYearly, df_gainWriYearly],
                            invert = [False, True],
                            xlabels = ["ND-GAIN score", "WRI score"],
                                       #"Per capita emissions " + "$(MtCO_{2})$", "Cumulative emissions " +"$(MtCO_{2})$"],
                            xlog = [False, False],
                            colours = ["#326b14", "#2a84ab"],
                            customPalette= ["#326b14", "#2a84ab"],
                            regression = True,                             
                            title ='') # want per sub-plot titles

#Clip out outliers
ax82.set_xlim([33, None]) #Note: flipped axis so 33 is upper bound, effectively removes Vanuvatu

#Move the legend
handles, labels = ax81.get_legend_handles_labels()
ax81.get_legend().remove() 
plt.legend_ = None
fig8.legend(handles, labels, loc='upper right', bbox_to_anchor=(1.1, 0.85),  
            bbox_transform=plt.gcf().transFigure)

for ax in axes8:
    ax.set_ylim([-0.005, None])


sns.scatterplot(data=dfEm, x="Per Capita", y="cumulative", hue="IAV - Mitigation score", ax=ax83, style="Region", 
                palette= cmap, alpha=1,
                edgecolor ="grey", linewidths = 0.5,
                legend=False,
                )
#axes
ax83.set_xscale("log")
ax83.set_yscale("log")
ax83.set_xlabel("Per capita emissions " + "$(MtCO_{2}  eq)$", weight="bold")
ax83.set_ylabel("Cumulative emissions " + "$(MtCO_{2}  eq)$", weight="bold")

#titles
ax81.set_title("a) Mitigation & IAV prevalence by ND-GAIN score", loc="left")
ax82.set_title("b) Mitigation & IAV prevalence by WRI score", loc="left")
ax83.set_title("c) Difference in IAV and mitigation topic scores by country emissions", loc="left")

#Add colour bar on separate axis
cticks = np.linspace(dfEm['IAV - Mitigation score'].min(), dfEm['IAV - Mitigation score'].max(), 7)
norm = mpl.colors.Normalize(vmin=cticks[0], vmax=cticks[-1])
cax = fig8.add_axes([.95, 0.12, 0.02, 0.33])
#ims = ax83.imshow(dfEm['IAV - Mitigation score'], cmap = cmap)
cbar = fig8.colorbar(mpl.cm.ScalarMappable(norm = norm, cmap=cmap), cax=cax, ticks=cticks, format='%0.2f') 
cbar.minorticks_off()
cbar.update_ticks()#Tick location is shifted otherwise
cax.set_ylabel("<- More IAV                          More mitigation ->",
           weight= 'bold', rotation=270, labelpad = 15)


fig8.tight_layout()

fig8.savefig(f'plots/{date.today()}VulnerabilityAndCombinedEmissions.png', bbox_inches='tight')
#%% correlations
#one
print(spearmanr(dfEm['Per Capita'], dfEm['Miti_avg']))

#%% correalations for whole df
dfEmSub = dfEm[['Miti_avg', 'IAV_avg', 'IAV - Mitigation score', 'CCT_avg', 'CRI_score_avg', 'Inform', 'gainYr', 'wriYr', 'Per Capita', 'cumulative']]
corDf_spearman = dfEmSub.corr(method='spearman')

def spearman_pOnly(x,y):
    return spearmanr(x,y)[1]

pvals = dfEmSub.corr(method=spearman_pOnly)

#Df with annotations
#anDf = corDf_spearman.astype(str) + '\np=' + pvals.astype(str)

plt.figure(figsize=(10,8), dpi=300)
heatmap = sns.heatmap(corDf_spearman, vmin=-1, vmax=1,
                      annot=True,
                      #annot=anDf, fmt = '',
                      annot_kws={"size": 10})

#%%Pearson
dfEmSub = dfEm[['Miti_avg', 'IAV_avg', 'IAV - Mitigation score', 'CCT_avg', 'gain_Avg', 'wri_Avg', 'gainYr', 'wriYr', 'Per Capita', 'cumulative']]
corDf_spearman = dfEmSub.corr(method='pearson')

def pearson_pOnly(x,y):
    return pearsonr(x,y)[1]

pvals = dfEmSub.corr(method=pearson_pOnly)

#Df with annotations
#anDf = corDf_spearman.astype(str) + '\np=' + pvals.astype(str)

plt.figure(figsize=(10,8), dpi=300)
heatmap = sns.heatmap(corDf_spearman, vmin=-1, vmax=1,
                      annot=True,
                      #annot=anDf, fmt = '',
                      annot_kws={"size": 10})

#%%
def spearman_pvalues(df):
    df = df.dropna()._get_numeric_data()
    dfcols = pd.DataFrame(columns=df.columns)
    correlates = dfcols.transpose().join(dfcols, how='outer')
    pvalues = dfcols.transpose().join(dfcols, how='outer')
    for r in df.columns:
        for c in df.columns:
            correlates[r][c] = spearmanr(df[r], df[c], nan_policy = 'omit')[0]
            pvalues[r][c] = spearmanr(df[r], df[c], nan_policy = 'omit')[1] 
    return(correlates, pvalues)

corDf_spearman, corDf_sP = spearman_pvalues(dfEm)

#Write to excel
writer = pd.ExcelWriter('SpearmanStats.xlsx', engine='xlsxwriter')

# Write each dataframe to a different worksheet.
corDf_spearman.to_excel(writer, sheet_name='Spearman correlation')
corDf_sP.to_excel(writer, sheet_name='p-values')

# Output the Excel file.
writer.save()
# Save and release handle
writer.close()
writer.handles = None